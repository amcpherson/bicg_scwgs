[["index.html", "Single Cell DNA Analysis Lab Chapter 1 Lab Overview 1.1 Instructions", " Single Cell DNA Analysis Lab Andrew McPherson 2021-06-07 Chapter 1 Lab Overview This book contains lab exercises for Module 05: Single Cell Genomics - DNA, as part of the Canadian Bioinformatics Workshop Cancer Analysis (CAN) Workshop. 1.1 Instructions Labs will use Rstudio. Each lab will be provided as blocks of R code you will copy-paste into Rstudio to follow the building of the predictor. Code blocks to be pasted will be in yellow like so. x &lt;- 5 If you hover your mouse over the block, you should see a little clipboard icon. Clicking on that icon will allow you to copy the block in one shot. I would use that. In each case, the result of executing a code block is shown directly after the code, in grey blocks like the one below. These are not intended to be pasted in. 5 "],["dlp-sequencing-of-an-ovarian-cancer-cell-line.html", "Chapter 2 DLP Sequencing of an Ovarian Cancer Cell Line 2.1 Introduction 2.2 Load the required packages 2.3 Read and QC the copy number data 2.4 Copy number exploration 2.5 Clustering 2.6 Subclonal Gene Amplification", " Chapter 2 DLP Sequencing of an Ovarian Cancer Cell Line 2.1 Introduction In this tutorial we will analyze the OV2295 cell line DLP data from the paper “Clonal Decomposition and DNA Replication States Defined by Scaled Single-Cell Genome Sequencing”, Laks et al. (2019) https://doi.org/10.1016/j.cell.2019.10.026. The OV2295 cell lines were generated from a primary, metastasis and relapse specimens obtained from a patient with high grade serous ovarian cancer (see Létourneau et al. (2012), https://doi.org/10.1186/1471-2407-12-379). The cell lines have a high degree of genomic instability, and significant genomic heterogeneity including with respect to large chromosomal changes. The data from the Laks et al. paper is deposited in zenodo (https://doi.org/10.5281/zenodo.3445364). 2.2 Load the required packages This tutorial will rely heavily on the tidyverse packages including ggplot2. Heatmap plotting will use ComplexHeatmap and manipulation of genomic segment data will be done with GenomicRanges. library(tidyverse) library(RColorBrewer) library(vroom) library(ggExtra) library(grid) library(factoextra) library(igraph) library(bluster) library(ggbeeswarm) library(umap) library(cluster) library(Homo.sapiens) library(ggpubr) 2.3 Read and QC the copy number data This data is available from zenodo and can be downloaded with: wget &quot;https://zenodo.org/record/3445364/files/ov2295_cell_cn.csv.gz&quot; wget &quot;https://zenodo.org/record/3445364/files/ov2295_cell_metrics.csv.gz&quot; The data was analyzed using the DLP single_cell_pipeline: https://github.com/shahcompbio/single_cell_pipeline. We will first read the metrics data, assess the quality of the cells and filter where necessary. The metrics file provided by the many columns but we will focus on quality and total_reads for filtering. Quality is calculated using a classifier trained on manually curated cell quality calls and uses many of the other metrics as features. metrics &lt;- vroom(&quot;ov2295_cell_metrics.csv.gz&quot;) DT::datatable( head(metrics), filter = &#39;top&#39;, options = list( pageLength=50, scrollX=&#39;400px&#39;, autoWidth=TRUE)) Plot a scatterplot of quality by total reads with marginals on the axes. The cloud of cells with significant read count and quality less than 0.75 are cells for which we cannot effectively predict copy number. These cells could either be cycling, or for which the genomic DNA degraded significantly prior to sequencing, or for which tagmentation failed. The plots in this notebook will be using ggplot extensively. I recommend the r4ds tutorials (https://r4ds.had.co.nz/data-visualisation.html) and the ggplot cheat sheet (https://github.com/rstudio/cheatsheets/blob/master/data-visualization-2.1.pdf) for further reference. p &lt;- metrics %&gt;% ggplot(mapping = aes(x=quality, y=total_reads)) + geom_point() + theme(legend.position = &quot;left&quot;) ggMarginal(p, type=&quot;histogram&quot;) Filter reads based on a quality threshold of 0.85 and a total read count threshold of 500k reads. Also filter control cells based on the experimental_condition and sample_id columns. metrics &lt;- metrics %&gt;% filter( quality &gt;= 0.85, total_reads &gt; 500000, !(experimental_condition %in% c(&quot;GM&quot;, &quot;gDNA&quot;)), sample_id %in% c(&quot;SA1090&quot;, &quot;SA921&quot;, &quot;SA922&quot;)) Read in the copy number data. Using vroom::vroom will significantly speed up data loading and using factors for chr and cell_id and ignoring irrelevant columns will reduce the memory footprint. cn &lt;- vroom( &#39;ov2295_cell_cn.csv.gz&#39;, col_types = cols( chr = col_factor(NULL), cell_id = col_factor(NULL) ), col_select = c( chr, start, end, reads, copy, state, cell_id ) ) Subset copy number data by the filtered cell ids in the metrics table. cn &lt;- cn %&gt;% inner_join(metrics[, c(&quot;cell_id&quot;, &quot;sample_id&quot;)], by = &quot;cell_id&quot;) knitr::kable(head(cn), booktabs = TRUE) chr start end reads copy state cell_id sample_id 1 1 500000 22 NA 5 SA922-A90554B-R28-C09 SA922 1 500001 1000000 609 NA 5 SA922-A90554B-R28-C09 SA922 1 1000001 1500000 752 4.574060 5 SA922-A90554B-R28-C09 SA922 1 1500001 2000000 672 3.465685 5 SA922-A90554B-R28-C09 SA922 1 2000001 2500000 931 5.571458 5 SA922-A90554B-R28-C09 SA922 1 2500001 3000000 794 NA 5 SA922-A90554B-R28-C09 SA922 2.4 Copy number exploration We will plot cells using a scatter plot of normalized binned read count data. The data has been processed through HMMCopy analysis as part of the DLP single cell pipeline. The state column contains the prediction of integer copy number state for each cell. The copy column is raw read count normalized for ploidy, gc, and mappability. We will plot copy on the y axis and color by state, and wrap the plotting code in a function for use below. plot_profile &lt;- function(cn) { cn.colors &lt;- c(rev(brewer.pal(n = 3, &quot;Blues&quot;))[1:2], &quot;#CCCCCC&quot;, tail(brewer.pal(n = 8, &quot;OrRd&quot;), 6)) cn.colors &lt;- c(cn.colors, cn.colors[c(9, 9, 9, 9)]) names(cn.colors) &lt;- 0:12 cn %&gt;% mutate(cn_state = factor(state, names(cn.colors))) %&gt;% mutate(chr = factor(chr, levels = c(1:22, &quot;X&quot;, &quot;Y&quot;))) %&gt;% ggplot() + geom_point(mapping = aes(x = start, y = copy, colour = cn_state), size = 0.5) + facet_grid(~chr, scales = &quot;free_x&quot;, space=&quot;free_x&quot;, switch = &quot;x&quot;) + theme(panel.spacing = unit(0.05, &quot;cm&quot;)) + scale_x_continuous(breaks = c()) + scale_color_manual(values = cn.colors, labels = names(cn.colors), drop = FALSE) + scale_y_continuous(breaks = seq(0, 8, by = 1), limit = c(0, 8)) + xlab(&#39;chromosome&#39;) } plot_cell &lt;- function(cn, plot_cell_id) { filter(cn, cell_id == plot_cell_id) %&gt;% plot_profile() } The first cell we will plot is a near diploid cell with some amplified regions and many LOH regions including chromosome 17. The chromosome 17 LOH overlaps with a deliterious TP53 mutation, as is typical of high grade serous ovarian cancers. plot_cell(cn, &quot;SA1090-A96213A-R30-C61&quot;) ## Warning: Removed 740 rows containing missing values (geom_point). A second cell from the same cell line appears to be baseline tetraploid. Many of the amplified or deleted regions overlap with those of the diploid baseline cell. Copy 3 regions on chromosome 2 and 15 support the tetraploid solution. plot_cell(cn, &quot;SA1090-A96213A-R28-C68&quot;) ## Warning: Removed 762 rows containing missing values (geom_point). It will be useful to plot all cells together in a heatmap for a high level look at the heterogeneity. Here we rely on the very useful ComplexHeatmap package. The plot takes a GenomicRanges object with columns as cells and rows as regions. A nice tutorial on GenomicRanges can be found here. The plot will use hierarchical clustering to order the cells and provide a summary of the similarity between groups of cells. plot_heatmap &lt;- function(gr, dist_method = &quot;euclidean&quot;){ #&#39; plot a heatmap with chromosome boundaries #&#39; the order of the rows can be customized here #&#39; its a simple distance based clustering #&#39; #&#39; Adapted from code published by Velazquez-Villarreal et al. (2020): #&#39; https://www.nature.com/articles/s42003-020-1044-8 #&#39; #&#39; Uses the very useful ComplexHeatmap package: #&#39; https://jokergoo.github.io/ComplexHeatmap-reference/book/ gr &lt;- GenomeInfoDb::sortSeqlevels(gr) gr &lt;- sort(gr) mat &lt;- as.matrix(GenomicRanges::mcols(gr)) mat &lt;- t(mat) hr &lt;- hclust(get_dist(mat, method = dist_method), method = &quot;average&quot;) hr = as.dendrogram(hr) # chromosome boundaries and midpoints for annotation chr_ids = GenomicRanges::seqnames(gr)@values chr_lengths = GenomicRanges::seqnames(gr)@lengths chr_props = chr_lengths / length(gr) mids = cumsum(chr_props) - (chr_props / 2) boundaries = cumsum(chr_props) boundaries = boundaries[1:length(boundaries)-1] abline_x = rep(boundaries, each=2) abline_y &lt;- rep(c(0,1), times=length(boundaries)) abline_ids &lt;- rep(1:length(boundaries),each=2) #annotation to label chromosomes ha_column = ComplexHeatmap::HeatmapAnnotation(cn = function(index) { grid.text(chr_ids,x=mids,y=1,just = c(&quot;center&quot;, &quot;top&quot;),gp=gpar(col=&quot;#202020&quot;,fontsize=6)) }) # the main heatmap cn.colors &lt;- c(rev(brewer.pal(n = 3, &quot;Blues&quot;))[1:2], &quot;#CCCCCC&quot;, tail(brewer.pal(n = 8, &quot;OrRd&quot;), 6)) cn.colors &lt;- c(cn.colors, cn.colors[c(9, 9, 9, 9)]) names(cn.colors) &lt;- 0:12 hm &lt;- ComplexHeatmap::Heatmap( matrix = mat, name = &quot;ploidy&quot;, col = cn.colors, cluster_rows = hr, cluster_columns = FALSE, show_row_names = FALSE, bottom_annotation = ha_column, column_title = &quot;CNV heatmap&quot;, use_raster = TRUE, ) ComplexHeatmap::draw(hm, row_dend_side = &quot;left&quot;) ComplexHeatmap::decorate_heatmap_body(&quot;ploidy&quot;, { grid.polyline( x = abline_x, y = abline_y, id = abline_ids, gp = gpar(lty = 1, lwd = 1)) }) } Plotting SA1090 (the primary sample), we can see that there are two major groups, a baseline diploid and a baseline tetraploid group. Both groups harbour additional heterogeneity. Looking closely, it appears that many of the patterns that distinguish populations within the diploid group are also found in the tetraploid group. gr &lt;- cn %&gt;% filter(sample_id == &quot;SA1090&quot;) %&gt;% dplyr::select(chr, start, end, state, cell_id) %&gt;% pivot_wider(names_from = cell_id, values_from = state) %&gt;% GenomicRanges::makeGRangesFromDataFrame(keep.extra.columns=TRUE,ignore.strand=TRUE) plot_heatmap(gr) The default distance method for generating the hierarchical clustering was eucldean, which will naturally result in large distances between diploid and tetraploid cells. Alternative distance methods can be specified, see the get_dist function from factoextras. If we use pearson correlation as the distance method, we see significant mixing of the diploid and tetraploid populations indicating that tetraploidization is occuring independently and sporadically throughout the population. plot_heatmap(gr, dist_method = &quot;pearson&quot;) If we plot total_reads by mean_copy (average ploidy) there appears to be a relationship, likely due to the fact that tetraploid cells will have twice the DNA available and take up more sequencing realestate. Classifying diploid and tetraploid, the difference in mean total_reads is highly significant, further evidence the tetraploid cells are truly tetraploid. Some cells classified as diploid may in fact be tetraploid with a perfect doubling of all chromosomes though this would be difficult to determine without orthogonal experiments. Note that we havent ruled out doublets with certainty. metrics %&gt;% filter(sample_id == &quot;SA1090&quot;) %&gt;% ggplot(aes(x=mean_copy, y=total_reads)) + geom_point() + geom_smooth(method=&#39;lm&#39;, formula= y~x) metrics %&gt;% filter(sample_id == &quot;SA1090&quot;) %&gt;% mutate(is_polyploid = mean_copy &gt; 2.5) %&gt;% ggplot(aes(x=is_polyploid, y=total_reads)) + geom_boxplot() + stat_compare_means(label.x = 1.3) 2.5 Clustering In order to further understand the population structure we can cluster the cells by their copy number profiles. It is worth noting that for some datasets, clustering is inappropriate. If the population of cells is continuously evolving and accruing neutral copy number changes, the cells will lie on a continuum of copy number change. Any maximal set of related cells could be considered a ‘cluster’ if a copy number change exists specific to that set of cells. In such a case phylogenetic representation is more appropriate. However, in many real datasets sets of cells will cluster due to either selection having favoured the expansion of some cell populations and the extinction of others. We will first cluster the cells using k-means. Independent segmentation of each cell using HMMCopy can produce small differences in segment boundaries that may affect clustering. We will thus cluster based on the raw copy number (‘copy’ column) instead of the HMMCopy state. Start by creating a matrix of raw copy number values, filtering bins with NaNs in any cell and scaling the data to allow clustering of cells with dissimilar ploidy. gr &lt;- cn %&gt;% dplyr::select(chr, start, end, copy, cell_id) %&gt;% pivot_wider(names_from = cell_id, values_from = copy) %&gt;% GenomicRanges::makeGRangesFromDataFrame(keep.extra.columns=TRUE,ignore.strand=TRUE) # Remove bins with any nan across any cell gr &lt;- gr[complete.cases(GenomicRanges::mcols(gr))] # Create matrix, remove bins that are nan across any cells mat &lt;- as.matrix(GenomicRanges::mcols(gr)) # Optionally normalize the copy number, this will group cells regardless of ploidy mat &lt;- scale(mat) mat &lt;- t(mat) We will then use PCA to transform the data to a reduced dimensionality representation. In bin level copy number data, many of the bins will be highly correlated especially with neighboring bins subject to the same copy number change. PCA will effectively compress multiple correlated bins into a single dimension. Working with the top PCA components will be desirable because it decreases the computational burden of downstream computation (ie clustering) and reduces noise by averaging across multiple bins. PCA can be run using the prcomp function: mat.pca &lt;- prcomp(mat) It can be informative to plot the PCA loadings of the top components. The loadings for a given component represent how much each bin contributes to that component. Large positive or negative values indicate a strong positive or negative correlation of the bin with the component respectively. Values close to 0 indicate the bin is uncorrelated with the component. The PCA loading plot can be helpful in identifying problematic noisy bins. These bins will show up as isolated spikes in the PCA loading plot. The first PCA plotted below looks unproblematic. Try setting the value of a bin to 1000 for a subset of cells and redoing the PCA to see the effect. pc = &quot;PC1&quot; gr.pca &lt;- granges(gr) GenomicRanges::mcols(gr.pca) &lt;- list(PC=mat.pca$rotation[, pc]) GenomicRanges::as.data.frame(gr.pca) %&gt;% tibble() %&gt;% dplyr::rename(chr=seqnames) %&gt;% ggplot() + geom_point(mapping = aes(x = start, y = PC), size = 0.5) + facet_grid(~chr, scales = &quot;free_x&quot;, space=&quot;free_x&quot;, switch = &quot;x&quot;) + theme(panel.spacing = unit(0.05, &quot;cm&quot;)) + scale_x_continuous(breaks = c()) + xlab(&#39;chromosome&#39;) Now run k-means on the first 50 PCs. Use 12 cluster centers and 100 restarts and set a seed for consistency. set.seed(42) clust.kmeans &lt;- kmeans(mat.pca$x[, 1:50], centers=12, nstart=100) clust &lt;- clust.kmeans$cluster UMAP is a non-linear dimensionality reduction technique favoured for its ability to preserve much of the structure of the data in a 2-D plot. We can use UMAP to visualize the clustering. mat.umap &lt;- umap(mat) mat.umap.tbl &lt;- tibble(x=mat.umap$layout[,1], y=mat.umap$layout[,2], cluster=factor(clust)) ggplot(mat.umap.tbl) + geom_point(aes(x=x, y=y, color=cluster)) We can also assess the clustering using the silhouette method. Briefly, the silhouette width statistic is calculated based on the mean distance of a datapoint to every other datapoint in the same cluster, and the mean distance to datapoints in the next closest cluster. A silhouette width less than 0 could indicate the cell may be better assigned to a different cluster, the cell is an outlier, or the data are not spherically distributed around cluster centers. sil.approx &lt;- approxSilhouette(mat, clusters=clust) sil.data &lt;- as.data.frame(sil.approx) sil.data$closest &lt;- factor(ifelse(sil.data$width &gt; 0, clust, sil.data$other)) sil.data$cluster &lt;- factor(clust) ggplot(sil.data, aes(x=cluster, y=width, colour=closest)) + ggbeeswarm::geom_quasirandom(method=&quot;smiley&quot;) We used k=12 cluster centers somewhat arbitrarily. Many strategies exist for selecting an appropriate value for k. For instance, we could use the gap statistic to select an optimal k as shown below. The optimal number of clusters suggested by this method may be less than expected reflecting the issues with clustering, especially k-means clustering, on this type of data. Generally speaking, differences between sub-populations will vary widely in scale with some populations well separated by large copy number changes and other derivative populations differing only by a few changes. gaps &lt;- clusGap(mat.pca$x[, 1:50], kmeans, K.max=30, B=100) ## Clustering k = 1,2,..., K.max (= 30): .. done ## Bootstrapping, b = 1,2,..., B (= 100) [one &quot;.&quot; per sample]: ## .................................................. 50 ## .................................................. 100 best.k &lt;- maxSE(gaps$Tab[,&quot;gap&quot;], gaps$Tab[,&quot;SE.sim&quot;]) as_tibble(gaps$Tab) %&gt;% mutate(k=factor(1:30)) %&gt;% ggplot() + geom_point(aes(x=k, y=gap)) + geom_vline(xintercept=best.k, col=&quot;red&quot;, lwd=0.5, lty=2) + xlab(&quot;Number of clusters&quot;) + ylab(&quot;Gap statistic&quot;) Alternative clustering approaches are possible, see this excellent scRNA tutorial for ideas. For instance, a graph based clustering approach could work better for clustering copy number data in some cases, as graph based methods will not favour spherical clusters. In order to visualize the cluster copy number, lets modify our heatmap plotting function to take in a clustering, order the rows by each cell’s cluster label, and annotate the clusters on the left side of the heatmap. plot_cluster_heatmap &lt;- function(gr, clust){ #&#39; plot a heatmap with chromosome boundaries #&#39; the order of the rows can be customized here #&#39; its a simple distance based clustering #&#39; #&#39; Adapted from code published by Velazquez-Villarreal et al. (2020): #&#39; https://www.nature.com/articles/s42003-020-1044-8 #&#39; #&#39; Uses the very useful ComplexHeatmap package: #&#39; https://jokergoo.github.io/ComplexHeatmap-reference/book/ gr &lt;- GenomeInfoDb::sortSeqlevels(gr) gr &lt;- sort(gr) sorted_clust = sort(clust) mat &lt;- as.matrix(GenomicRanges::mcols(gr)) mat &lt;- t(mat) mat &lt;- mat[names(sorted_clust),] # chromosome boundaries and midpoints for annotation chr_ids = GenomicRanges::seqnames(gr)@values chr_lengths = GenomicRanges::seqnames(gr)@lengths chr_props = chr_lengths / length(gr) mids = cumsum(chr_props) - (chr_props / 2) boundaries = cumsum(chr_props) boundaries = boundaries[1:length(boundaries)-1] abline_x = rep(boundaries, each=2) abline_y &lt;- rep(c(0,1), times=length(boundaries)) abline_ids &lt;- rep(1:length(boundaries),each=2) # annotation to label chromosomes ha_column = ComplexHeatmap::HeatmapAnnotation(cn = function(index) { grid.text(chr_ids,x=mids,y=1,just = c(&quot;center&quot;, &quot;top&quot;),gp=gpar(col=&quot;#202020&quot;,fontsize=6)) }) # cluster annotation cluster_colors = rainbow(length(unique(sorted_clust))) names(cluster_colors) = unique(sorted_clust) ha_row = ComplexHeatmap::rowAnnotation(cluster = factor(sorted_clust), col = list(cluster = cluster_colors)) # the main heatmap cn.colors &lt;- c(rev(brewer.pal(n = 3, &quot;Blues&quot;))[1:2], &quot;#CCCCCC&quot;, tail(brewer.pal(n = 8, &quot;OrRd&quot;), 6)) cn.colors &lt;- c(cn.colors, cn.colors[c(9, 9, 9, 9)]) names(cn.colors) &lt;- 0:12 hm = ComplexHeatmap::Heatmap( matrix = mat, name = &quot;ploidy&quot;, col = cn.colors, cluster_rows = FALSE, cluster_columns = FALSE, show_row_names = FALSE, bottom_annotation = ha_column, left_annotation = ha_row, column_title = &quot;CNV heatmap&quot;, use_raster = TRUE, ) ComplexHeatmap::draw(hm) ComplexHeatmap::decorate_heatmap_body(&quot;ploidy&quot;, { grid.polyline( x = abline_x, y = abline_y, id = abline_ids, gp = gpar(lty = 1, lwd = 1)) }) } gr &lt;- cn %&gt;% dplyr::select(chr, start, end, state, cell_id) %&gt;% pivot_wider(names_from = cell_id, values_from = state) %&gt;% GenomicRanges::makeGRangesFromDataFrame(keep.extra.columns=TRUE,ignore.strand=TRUE) plot_cluster_heatmap(gr, clust) We can also merge cell copy number data by cluster to show aggregate cluster level copy number. clust.df &lt;- enframe(clust.kmeans$cluster) %&gt;% dplyr::rename(cell_id = name, cluster = value) clust.sizes &lt;- enframe(table(clust.df$cluster)) %&gt;% dplyr::rename(cell_id = name, size = value) %&gt;% filter(size &gt;= 10) cn_clust &lt;- cn %&gt;% inner_join(clust.df) %&gt;% group_by(chr, start, end, cluster) %&gt;% summarize(copy = mean(copy), state = median(state)) ## Joining, by = &quot;cell_id&quot; ## `summarise()` has grouped output by &#39;chr&#39;, &#39;start&#39;, &#39;end&#39;. You can override using the `.groups` argument. cn_clust %&gt;% filter(cluster == 7) %&gt;% plot_profile() ## Warning: Removed 806 rows containing missing values (geom_point). cn_clust %&gt;% filter(cluster == 8) %&gt;% plot_profile() ## Warning: Removed 959 rows containing missing values (geom_point). cn_clust %&gt;% filter(cluster == 9) %&gt;% plot_profile() ## Warning: Removed 915 rows containing missing values (geom_point). There appears to be a deletion on chromosome 5. Navigate here to see why: http://genome.ucsc.edu/cgi-bin/hgTracks?db=hg19&amp;lastVirtModeType=default&amp;lastVirtModeExtraState=&amp;virtModeType=default&amp;virtMode=0&amp;nonVirtPosition=&amp;position=chr5%3A67500000%2D72000002&amp;hgsid=1117136619_dGtW3EEOeJAIG6cYbSGFZwGwyLzb subset.gr &lt;- cn_clust %&gt;% filter(copy &lt; 0.2, chr != &quot;Y&quot;) %&gt;% makeGRangesFromDataFrame() knitr::kable(subset.gr, booktabs = TRUE) seqnames start end width strand 5 69000001 69500000 5e+05 * 5 69000001 69500000 5e+05 * 5 69000001 69500000 5e+05 * 5 69000001 69500000 5e+05 * 5 69000001 69500000 5e+05 * 5 69000001 69500000 5e+05 * 5 69500001 70000000 5e+05 * 5 69500001 70000000 5e+05 * 5 69500001 70000000 5e+05 * 5 69500001 70000000 5e+05 * 5 69500001 70000000 5e+05 * 5 69500001 70000000 5e+05 * 5 69500001 70000000 5e+05 * 5 69500001 70000000 5e+05 * 5 70000001 70500000 5e+05 * 5 70000001 70500000 5e+05 * 5 70000001 70500000 5e+05 * 5 70000001 70500000 5e+05 * 2.6 Subclonal Gene Amplification Finally, lets look at the gene content of some of the high level amplifications. First read in a list of known oncogenic amplified genes from the cancer gene census. Read hg19 genes from TxDb.Hsapiens.UCSC.hg19.knownGene and be careful to rename chromosomes, ie “chr9” -&gt; “9”. Add gene symbols from org.Hs.egSYMBOL. cencus.amps &lt;- read_csv(&#39;./Census_ampThu\\ Apr\\ 16\\ 15_35_36\\ 2020.csv&#39;) %&gt;% dplyr::rename(symbol = `Gene Symbol`) ## ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────── ## cols( ## `Gene Symbol` = col_character(), ## Name = col_character(), ## `Entrez GeneId` = col_double(), ## `Genome Location` = col_character(), ## Tier = col_double(), ## `Tumour Types(Somatic)` = col_character(), ## Synonyms = col_character() ## ) # read human genes, normalize chromosome names human.genes &lt;- genes(TxDb.Hsapiens.UCSC.hg19.knownGene) ## 403 genes were dropped because they have exons located on both strands of the same reference sequence or on ## more than one reference sequence, so cannot be represented by a single genomic range. ## Use &#39;single.strand.genes.only=FALSE&#39; to get all the genes in a GRangesList object, or use suppressMessages() ## to suppress this message. human.genes &lt;- renameSeqlevels(human.genes, sub(&quot;chr&quot;, &quot;&quot;, seqlevels(human.genes))) # add gene symbol from org.Hs.egSYMBOL GenomicRanges::mcols(human.genes) &lt;- tibble(gene_id=human.genes$gene_id) %&gt;% left_join(tibble(as.data.frame(org.Hs.egSYMBOL))) ## Joining, by = &quot;gene_id&quot; # subset by cancer gene cencus amps cencus.amps.genes &lt;- human.genes[(elementMetadata(human.genes)[,&#39;symbol&#39;] %in% cencus.amps$symbol)] Filter copy number for high level events, then subset by overlap with gene regions. The SOX2 gene is amplified. subset.gr &lt;- cn_clust %&gt;% filter(copy &gt; 10) %&gt;% makeGRangesFromDataFrame(keep.extra.columns=TRUE,ignore.strand=TRUE) subset.genes &lt;- subsetByOverlaps(cencus.amps.genes, subset.gr) knitr::kable(subset.genes, booktabs = TRUE) seqnames start end width strand gene_id symbol 3 181429712 181432223 2512 + 6657 SOX2 Overlapping the SOX2 region with all cluster copy number we find that SOX2 is subclonally amplified. all.gr &lt;- cn_clust %&gt;% makeGRangesFromDataFrame(keep.extra.columns=TRUE,ignore.strand=TRUE) subsetByOverlaps(all.gr, subset.genes) %&gt;% as_tibble() %&gt;% ggplot() + geom_col(aes(x=factor(cluster), y=copy)) "],["targeted-snv-sequencing-of-an-all-sample.html", "Chapter 3 Targeted SNV Sequencing of an ALL Sample 3.1 Introduction 3.2 Load the required packages 3.3 Read the data 3.4 Data QC 3.5 Heatmap plots 3.6 SCIΦ Phylogeny", " Chapter 3 Targeted SNV Sequencing of an ALL Sample 3.1 Introduction In this tutorial we will analyze targeted single cell sequencing data from a patient with Acute Lymphoblastic Leukemia. The data was generated as part of a study of six ALL patients (see Gawad et al.). The data we will analyze corresponds to “Patient 3” from that paper. The data was also reanalyzed by Singer et al. to showcase their novel phylogenetic method SCIPhI. We have used pipelines provided alongside the SCIPhI code to generate a table of mutation data and a predicted phylogenetic tree. 3.2 Load the required packages This tutorial will rely heavily on the tidyverse packages including ggplot2. Heatmap plotting will use ComplexHeatmap. library(tidyverse) library(ggtree) library(phytools) library(vcfR) library(phylogram) 3.3 Read the data The SCIPhI pipeline produced an mpileup. We have further processed this data using samtools and bcftools to produce a multi-sample VCF. The VCF can be read into a dataframe using the vcfR package. We will read the vcf, then extract the total read count and variant read counts (DP and DV in the vcf). We will put the data into ‘tidy’ format and merge. vcf_filename = &quot;cell_variants.vcf&quot; vcf &lt;- read.vcfR(vcf_filename, verbose = TRUE) ## Scanning file to determine attributes. ## File attributes: ## meta lines: 118 ## header_line: 119 ## variant count: 62 ## column count: 264 ## Meta line 118 read in. ## All meta lines processed. ## gt matrix initialized. ## Character matrix gt created. ## Character matrix gt rows: 62 ## Character matrix gt cols: 264 ## skip: 0 ## nrows: 62 ## row_num: 0 ## Processed variant: 62 ## All variants processed total_count &lt;- extract.gt(vcf, element = &#39;DP&#39;, as.numeric = TRUE) %&gt;% as_tibble(rownames=&#39;position&#39;) %&gt;% pivot_longer(!position, names_to = &quot;cell_id&quot;, values_to = &quot;total_count&quot;) variant_count &lt;- extract.gt(vcf, element = &#39;DV&#39;, as.numeric = TRUE) %&gt;% as_tibble(rownames=&#39;position&#39;) %&gt;% pivot_longer(!position, names_to = &quot;cell_id&quot;, values_to = &quot;variant_count&quot;) read_counts &lt;- full_join(total_count, variant_count) ## Joining, by = c(&quot;position&quot;, &quot;cell_id&quot;) knitr::kable(head(read_counts), booktabs = TRUE) position cell_id total_count variant_count chr1_6184265 Patient_3_Cell_S10 280 0 chr1_6184265 Patient_3_Cell_S100 917 1 chr1_6184265 Patient_3_Cell_S101 1056 3 chr1_6184265 Patient_3_Cell_S102 579 1 chr1_6184265 Patient_3_Cell_S103 134 0 chr1_6184265 Patient_3_Cell_S104 872 0 3.4 Data QC Poor performing cells will have consistently low depth (total read count) across all positions. Plot a boxplot of log transformed total read count, ordering by mean total read count for readability. ggplot(read_counts, aes(x=reorder(cell_id, total_count+1, FUN = median), y=total_count+1)) + geom_boxplot() + scale_y_continuous(trans=&#39;log10&#39;) + scale_x_discrete(labels = NULL, breaks = NULL) + labs(x = &quot;&quot;) The left side of the plot show several poor quality cells. A plot of mean total read count confirms there are outlier cells. Filter these cells using a threshold of 400 mean total read count. mean_total_counts &lt;- read_counts %&gt;% group_by(cell_id) %&gt;% summarise( mean_total_counts = mean(total_count) ) ggplot(mean_total_counts) + geom_histogram(aes(x=mean_total_counts), bins=30) filtered_read_counts &lt;- read_counts %&gt;% inner_join( mean_total_counts %&gt;% filter(mean_total_counts &gt; 400)) ## Joining, by = &quot;cell_id&quot; Identify poor performing variant positions characterized by low depth across all cells. A caveat to this plot is that low total depth may be caused by copy number change. Most variants appear to perform well in this dataset. ggplot(filtered_read_counts, aes(y=reorder(position, total_count+1, FUN = median), x=total_count+1)) + geom_boxplot() + scale_x_continuous(trans=&#39;log10&#39;) + ylab(&quot;position&quot;) Identify consistently low vaf variant positions likely to not exist at all in the cell population. filtered_read_counts %&gt;% mutate(vaf = (variant_count) / (total_count)) %&gt;% replace_na(list(vaf=0)) %&gt;% ggplot(aes(y=reorder(position, vaf, FUN = mean), x=vaf)) + geom_boxplot() + ylab(&quot;variant&quot;) 3.5 Heatmap plots Heatmap plots of a matrix of cell by variant data will show how cells cluster into subpopulations, and variants cluster by their shared evolutionary history. Convert the filtered read counts to a matrix of variant allele frequency. Black denotes cells with no data, instances where we failed to sequence reads for a variant in the given cell. Note the block structure due to the clonal populations with shared variants. However, also note that within each block there is a considerable amount of noise with many variants having a lower than expected VAF. This is very likely the results of allelic dropout. Note there appears to be a poor quality position at chr11_48347394, in the middle of the heatmap. mat &lt;- filtered_read_counts %&gt;% mutate(vaf = variant_count / total_count) %&gt;% dplyr::select(c(&quot;position&quot;, &quot;cell_id&quot;, &quot;vaf&quot;)) %&gt;% pivot_wider(names_from=cell_id, values_from=vaf) %&gt;% column_to_rownames(&quot;position&quot;) %&gt;% as.matrix() row_hr &lt;- hclust(dist(mat), method = &quot;average&quot;) row_hr = as.dendrogram(row_hr) column_hr &lt;- hclust(dist(t(mat)), method = &quot;average&quot;) column_hr = as.dendrogram(column_hr) ComplexHeatmap::Heatmap( mat, name=&quot;VAF&quot;, cluster_rows=row_hr, cluster_columns=column_hr, na_col=&quot;black&quot;, show_row_names=FALSE, show_column_names=FALSE, ) It can be instructive to also plot total read count as this gives an approximate estimate of total copy number. Try to identify the variants in regions of low copy number that are also homozygous (VAF 1) as determined from the plot above. mat &lt;- filtered_read_counts %&gt;% dplyr::select(c(&quot;position&quot;, &quot;cell_id&quot;, &quot;total_count&quot;)) %&gt;% pivot_wider(names_from=cell_id, values_from=total_count) %&gt;% column_to_rownames(&quot;position&quot;) %&gt;% as.matrix() ComplexHeatmap::Heatmap( mat, name=&quot;Depth&quot;, cluster_rows=row_hr, cluster_columns=column_hr, na_col=&quot;black&quot;, show_row_names=FALSE, show_column_names=FALSE, ) ## The automatically generated colors map from the 1^st and 99^th of the values in the matrix. There are outliers ## in the matrix whose patterns might be hidden by this color mapping. You can manually set the color to `col` ## argument. ## ## Use `suppressMessages()` to turn off this message. 3.6 SCIΦ Phylogeny SCIΦ is a method for jointly calling mutations in individual cells and estimating the phylogeny relating those cells. The method uses MCMC sampling to genotype mutations and predict a tree and is robust to high drop-out and missing data. The input to SCIΦ is an mpileup file produced by samtools. SCIΦ has been run for you on the Patient 3 data. The output os a tree in dot format, a vcf of mutation genotypes per cell and a table of posterior genotype probabilities per cell per mutation. Some wrangling was required to convert from dot format to a format that can be read by R (newick). Read in the resulting newick file and plot using ggtree. Note that the tree has no branch length information as this is not part of the SCIΦ model. # Read the tree as a dendrogram object sciphi.tree &lt;- read.dendrogram(&quot;exp_short_tree.newick&quot;) # Show a plot of the tree ggtree(read.newick(&quot;exp_short_tree.newick&quot;)) We will plot the predicted tree together with the heatmap. To do so we will have to reorder the columns of the heatmap to coincide with the order of the leaves of the tree. The matrix has columns labeled by cell_id. The tree has nodes labeled by a node label. We will need to create a mapping between these two. A table of node information will help as it contains cell ids for nodes that are leaves. Read in a table of node information, extract a node to cell mapping and use that to create a cell_id ordering that matches the tree. # Read the table of node information sciphi.nodes &lt;- read_csv(&quot;exp_short_nodes.csv&quot;) ## ## ── Column specification ──────────────────────────────────────────────────────────────────────────────────────────────────── ## cols( ## node = col_double(), ## style = col_character(), ## fillcolor = col_character(), ## label = col_character(), ## shape = col_character(), ## is_leaf = col_logical(), ## cell_id = col_character() ## ) # Create a table mapping &#39;node&#39; to cell_id leaf_cell_nodes &lt;- sciphi.nodes %&gt;% filter(is_leaf) %&gt;% dplyr::select(cell_id, node) %&gt;% mutate(node = as.character(node)) %&gt;% column_to_rownames(&quot;node&quot;) # Identify the order of nodes in the dendrogram leaf_cell_order = leaf_cell_nodes[labels(sciphi.tree), &quot;cell_id&quot;] The tree contains all cells, thus we will use the full dataset to construct a matrix for the heatmap. Re-order the columns of the matrix according to the tree, then use the tree dendrogram object in our call to ComplexHeatmap::Heatmap. Look for noteable differences from the hierarchical clustering dendrogram above. # Re-create the matrix of vaf with all cells and variants mat &lt;- read_counts %&gt;% mutate(vaf = variant_count / total_count) %&gt;% dplyr::select(c(&quot;position&quot;, &quot;cell_id&quot;, &quot;vaf&quot;)) %&gt;% pivot_wider(names_from=cell_id, values_from=vaf) %&gt;% column_to_rownames(&quot;position&quot;) %&gt;% as.matrix() # Reorder the matrix according to the tree mat = mat[, leaf_cell_order] ComplexHeatmap::Heatmap( mat, name = &quot;VAF&quot;, cluster_rows = TRUE, cluster_columns = sciphi.tree, show_row_names=FALSE, show_column_names=FALSE, ) "]]
